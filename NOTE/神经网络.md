#ComputerScience/AI/ML   
# 1. 背景
传统机器学习的问题是需要我们先根据数据的特点假定一个函数, 将其参数化后进行拟合.  
神经网络就解决了这个问题, 它可以拟合任意函数, 不需要人为假定.  

构建一个模型, 就是定义一个假设函数.  

# 2. 逻辑回归
逻辑回归就是在线性回归的计算结果上,增加了一个$Sigmoid$激活函数.
$LogisticRegression(x)=Sigmoid(LinearRegression(x))=Sigmoid(wx+b)$

$Sigmoid$函数的作用是可以将大于0的数快速映射到接近1,小于0的数快速映射到接近0.  

在逻辑回归里, $Sigmoid$ 函数的输入是线性回归的结果,所以线性回归的作用,就是将$Feature$通过参数 $w$ 和 $b$ 的线性变化,让正例的线性变化结果大于$0$,让负例的线性变化结果小于$0$,再由Sigmoid函数将线性回归的结果映射到 $0 \sim 1$ 之间.  

在深度学习里, 输入先经过一个线性变换, 然后嵌套一个非线性函数, 这个非线性函数就叫作[[激活函数]]. 激活函数的作用就是在线性函数的基础上增加了非线性.  

# 3. 数据集划分

**训练集** 训练集的作用就是训练模型,训练集上的数据你会使用很多次,跑很多迭代.用它来调整模型的参数.

**验证集** 验证集是帮助你在训练过程中评估模型的性能,它并没有被拿来训练模型.根据验证集的评估结果,你可以调整模型的超参数,比如调整学习率,或者增加特征的高次项等.验证集的数据你使用的比训练集要少.只在模型训练到一定阶段,评估模型的性能表现.

**测试集** 测试集是你训练好了模型,最后只使用一次,评价模型的最终真实表现的.  

# 4. 拟合 
> [!note]  容易导致过拟合的原因
> 训练迭代次数太多会导致模型记住所有数据.  

# 5. 神经网络的多分类  
> [!note] Logits
> 对于神经网络,输出层经过线性回归,还没有经过激活函数的值叫做 Logits.  
> Logits经过激活函数后就是最终的输出值了.  

在输出层,得到 Logits 后激活函数选用[[激活函数#5. Softmax]].  
损失函数使用[[交叉熵损失函数]].







 


