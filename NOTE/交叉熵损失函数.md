#ComputerScience/AI/ML/Loss  
对于交叉熵损失函数, 我们做如下假设:  
- 类别个数为 C.
- 真实标签用 one-hot 向量(独热编码)表示.
- 预测的概率分布是 $p = (p_1,p_2,\cdots, p_C)$

其定义为:
$$Loss = -\sum^{C}_{i = 1}y_i\log(p_i)$$
对于一个具体的样本, 则是:  
$$Loss = -\log(p)$$
对于批量样本, Batch Size 为 N 时:  
$$Loss = -\frac{1}{N}\sum^{N}_{n = 1}\sum^{C}_{i = 1}y^n_i\log(p^n_i)$$
